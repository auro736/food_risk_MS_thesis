{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from TRC.models import ModelForWeightedSequenceClassification\n",
    "from common_utils import extract_from_dataframe, mask_batch_seq_generator, pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "ASSIGN_WEIGHT = True\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_name = 'roberta-large'\n",
    "\n",
    "model_path = '/home/cc/rora_tesi_new/log/log_TRC/roberta-large/bertweet-seq/20_epoch/data/True_weight/42_seed/saved-model/pytorch_model.bin'\n",
    "config_path = '/home/cc/rora_tesi_new/log/log_TRC/roberta-large/bertweet-seq/20_epoch/data/True_weight/42_seed/saved-model/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_model(model_path, config_path, device, model_name):\n",
    "\n",
    "    config = config = AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    model = ModelForWeightedSequenceClassification(model_name=model_name,config=config)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_weight(Y_train):\n",
    "    # weight of each class in loss function\n",
    "    class_weight = [np.array(Y_train).shape[0] / (np.array(Y_train) == i).sum() for i in range(len(set(Y_train)))]\n",
    "    class_weight = torch.FloatTensor(class_weight)\n",
    "    return class_weight\n",
    "\n",
    "def prepare_data(data_path, need_columns):\n",
    "\n",
    "    data = pd.read_pickle(data_path)\n",
    "    X, Y = extract_from_dataframe(data, need_columns)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/home/cc/rora_tesi_new/data/train.p'\n",
    "test_data_path = '/home/cc/rora_tesi_new/data/test.p'\n",
    "\n",
    "need_columns = ['tweet_tokens', 'sentence_class']\n",
    "\n",
    "_, Y_train = prepare_data(train_data_path, need_columns)\n",
    "X_test_raw, Y_test = prepare_data(test_data_path, need_columns)\n",
    "\n",
    "test_batch_size = Y_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = None\n",
    "if ASSIGN_WEIGHT:\n",
    "    class_weight = create_weight(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, normalization = True)\n",
    "model = load_local_model(model_path, config_path, device, model_name)\n",
    "model = model.to(device)\n",
    "labels = sorted(model.config.label2id, key=model.config.label2id.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(orig_tokens, tokenizer):\n",
    "    \"\"\"\n",
    "    tokenize a array of raw text\n",
    "    \"\"\"\n",
    "    # bert_tokens = [\"[CLS]\"]\n",
    "    bert_tokens = [tokenizer.cls_token]\n",
    "    for x in orig_tokens:\n",
    "        bert_tokens.extend(tokenizer.tokenize(x))\n",
    "    # bert_tokens.append(\"[SEP]\")\n",
    "    bert_tokens.append(tokenizer.sep_token)\n",
    "    return bert_tokens\n",
    "\n",
    "def tokenize_with_new_mask(orig_text, max_length, tokenizer):\n",
    "    \"\"\"\n",
    "    tokenize a array of raw text and generate corresponding\n",
    "    attention labels array and attention masks array\n",
    "    \"\"\"\n",
    "    bert_tokens = [simple_tokenize(t, tokenizer) for t in orig_text]\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in bert_tokens]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    attention_masks = []\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i > 0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    attention_masks = np.array(attention_masks)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, masks_test = tokenize_with_new_mask(X_test_raw, MAX_LENGTH, tokenizer)\n",
    "\n",
    "num_batches = X_test.shape[0] // test_batch_size\n",
    "test_batch_generator = mask_batch_seq_generator(X_test, Y_test, masks_test, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X_test_raw, model, device, class_weight):\n",
    "    \n",
    "    X_test, masks_test = tokenize_with_new_mask(X_test_raw, MAX_LENGTH, tokenizer)\n",
    "\n",
    "    num_batches = X_test.shape[0] // test_batch_size\n",
    "    test_batch_generator = mask_batch_seq_generator(X_test, Y_test, masks_test, test_batch_size)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in tqdm(range(num_batches)):\n",
    "            x_batch, y_batch, masks_batch = next(test_batch_generator)\n",
    "            if len(x_batch.shape) == 3:\n",
    "                x_batch = Variable(torch.FloatTensor(x_batch)).to(device)\n",
    "            else:\n",
    "                x_batch = Variable(torch.LongTensor(x_batch)).to(device)\n",
    "            y_batch = y_batch.astype(np.float64)\n",
    "            y_batch = Variable(torch.LongTensor(y_batch)).to(device)\n",
    "            masks_batch = Variable(torch.FloatTensor(masks_batch)).to(device)\n",
    "            class_weight = class_weight.to(device) if class_weight is not None else None\n",
    "            outputs = model(x_batch, masks_batch, labels=y_batch, class_weight=class_weight)\n",
    "            print(outputs)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "    return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(f, tokenizer, output_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logits' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(f(X_test_raw[\u001b[39m1\u001b[39;49m], model, device, class_weight))\n",
      "Cell \u001b[0;32mIn[98], line 25\u001b[0m, in \u001b[0;36mf\u001b[0;34m(X_test_raw, model, device, class_weight)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[39mprint\u001b[39m(outputs)\n\u001b[1;32m     23\u001b[0m         loss, logits \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'logits' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print(f(X_test_raw[1], model, device, class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[39m=\u001b[39m explainer(X_test[\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/explainers/_partition.py:136\u001b[0m, in \u001b[0;36mPartition.__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, max_evals\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, fixed_context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, main_effects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, error_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m              outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, silent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Explain the output of the model on the given arguments.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\n\u001b[1;32m    137\u001b[0m         \u001b[39m*\u001b[39;49margs, max_evals\u001b[39m=\u001b[39;49mmax_evals, fixed_context\u001b[39m=\u001b[39;49mfixed_context, main_effects\u001b[39m=\u001b[39;49mmain_effects, error_bounds\u001b[39m=\u001b[39;49merror_bounds, batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    138\u001b[0m         outputs\u001b[39m=\u001b[39;49moutputs, silent\u001b[39m=\u001b[39;49msilent\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/explainers/_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     feature_names \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(args))]\n\u001b[1;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m row_args \u001b[39min\u001b[39;00m show_progress(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39margs), num_rows, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m explainer\u001b[39m\u001b[39m\"\u001b[39m, silent):\n\u001b[0;32m--> 266\u001b[0m     row_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain_row(\n\u001b[1;32m    267\u001b[0m         \u001b[39m*\u001b[39;49mrow_args, max_evals\u001b[39m=\u001b[39;49mmax_evals, main_effects\u001b[39m=\u001b[39;49mmain_effects, error_bounds\u001b[39m=\u001b[39;49merror_bounds,\n\u001b[1;32m    268\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size, outputs\u001b[39m=\u001b[39;49moutputs, silent\u001b[39m=\u001b[39;49msilent, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     values\u001b[39m.\u001b[39mappend(row_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    271\u001b[0m     output_indices\u001b[39m.\u001b[39mappend(row_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39moutput_indices\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/explainers/_partition.py:154\u001b[0m, in \u001b[0;36mPartition.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown fixed_context value passed (must be 0, 1 or None): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39mfixed_context)\n\u001b[1;32m    153\u001b[0m \u001b[39m# build a masked version of the model for the current input sample\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m fm \u001b[39m=\u001b[39m MaskedModel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasker, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinearize_link, \u001b[39m*\u001b[39;49mrow_args)\n\u001b[1;32m    156\u001b[0m \u001b[39m# make sure we have the base value and current value outputs\u001b[39;00m\n\u001b[1;32m    157\u001b[0m M \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(fm)\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/utils/_masked_model.py:28\u001b[0m, in \u001b[0;36mMaskedModel.__init__\u001b[0;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# if the masker supports it, save what positions vary from the background\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasker, \u001b[39m\"\u001b[39m\u001b[39minvariants\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants \u001b[39m=\u001b[39m \u001b[39m~\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasker\u001b[39m.\u001b[39;49minvariants(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants_column_sums \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants_row_inds \u001b[39m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants[:,i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     32\u001b[0m     ]\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/maskers/_text.py:295\u001b[0m, in \u001b[0;36mText.invariants\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvariants\u001b[39m(\u001b[39mself\u001b[39m, s):\n\u001b[1;32m    293\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" The names of the features for each mask position for the given input string.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_s_cache(s)\n\u001b[1;32m    297\u001b[0m     invariants \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenized_s), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool)\n\u001b[1;32m    298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_prefix \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/maskers/_text.py:274\u001b[0m, in \u001b[0;36mText._update_s_cache\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_s \u001b[39m!=\u001b[39m s:\n\u001b[1;32m    273\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_s \u001b[39m=\u001b[39m s\n\u001b[0;32m--> 274\u001b[0m     tokens, token_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_segments(s)\n\u001b[1;32m    275\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenized_s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(token_ids)\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_segments_s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(tokens)\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/shap/maskers/_text.py:170\u001b[0m, in \u001b[0;36mText.token_segments\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Returns the substrings associated with each token in the given string.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     token_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(s, return_offsets_mapping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    171\u001b[0m     offsets \u001b[39m=\u001b[39m token_data[\u001b[39m\"\u001b[39m\u001b[39moffset_mapping\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    172\u001b[0m     offsets \u001b[39m=\u001b[39m [(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m o \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m o \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m offsets]\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2548\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2547\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2548\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2549\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2550\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/venv/rora_venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2606\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2606\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2607\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2608\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2609\u001b[0m     )\n\u001b[1;32m   2611\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2612\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2613\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2614\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2615\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "shap_values = explainer(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rora_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
